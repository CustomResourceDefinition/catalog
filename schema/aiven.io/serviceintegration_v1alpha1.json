{
  "description": "ServiceIntegration is the Schema for the serviceintegrations API.\n\ninfo \"Adoption of existing integrations\": If a ServiceIntegration resource is created with configuration matching an existing Aiven integration (created outside the operator), the operator will adopt the existing integration.",
  "type": "object",
  "properties": {
    "apiVersion": {
      "description": "APIVersion defines the versioned schema of this representation of an object.\nServers should convert recognized schemas to the latest internal value, and\nmay reject unrecognized values.\nMore info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources",
      "type": "string"
    },
    "kind": {
      "description": "Kind is a string value representing the REST resource this object represents.\nServers may infer this from the endpoint the client submits requests to.\nCannot be updated.\nIn CamelCase.\nMore info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds",
      "type": "string"
    },
    "metadata": {
      "type": "object"
    },
    "spec": {
      "description": "ServiceIntegrationSpec defines the desired state of ServiceIntegration",
      "type": "object",
      "required": [
        "integrationType",
        "project"
      ],
      "properties": {
        "authSecretRef": {
          "description": "Authentication reference to Aiven token in a secret",
          "type": "object",
          "required": [
            "key",
            "name"
          ],
          "properties": {
            "key": {
              "type": "string",
              "minLength": 1
            },
            "name": {
              "type": "string",
              "minLength": 1
            }
          },
          "additionalProperties": false
        },
        "autoscaler": {
          "description": "Autoscaler specific user configuration options",
          "type": "object"
        },
        "clickhouseKafka": {
          "description": "Clickhouse Kafka configuration values",
          "type": "object",
          "properties": {
            "tables": {
              "description": "Array of table configurations that define how Kafka topics are mapped to ClickHouse tables. Each table configuration specifies the table structure, associated Kafka topics, and read/write settings.",
              "type": "array",
              "maxItems": 400,
              "items": {
                "description": "Table to create",
                "type": "object",
                "required": [
                  "columns",
                  "data_format",
                  "group_name",
                  "name",
                  "topics"
                ],
                "properties": {
                  "auto_offset_reset": {
                    "description": "Determines where to start reading from Kafka when no offset is stored or the stored offset is out of range. 'earliest' starts from the beginning, 'latest' starts from the end.",
                    "type": "string",
                    "enum": [
                      "beginning",
                      "earliest",
                      "end",
                      "largest",
                      "latest",
                      "smallest"
                    ]
                  },
                  "columns": {
                    "description": "Array of column definitions that specify the structure of the ClickHouse table. Each column maps to a field in the Kafka messages.",
                    "type": "array",
                    "maxItems": 100,
                    "items": {
                      "description": "Table column",
                      "type": "object",
                      "required": [
                        "name",
                        "type"
                      ],
                      "properties": {
                        "name": {
                          "description": "The name of the column in the ClickHouse table. This should match the field names in your Kafka message format.",
                          "type": "string",
                          "maxLength": 40,
                          "minLength": 1
                        },
                        "type": {
                          "description": "The ClickHouse data type for this column. Must be a valid ClickHouse data type that can handle the data format.",
                          "type": "string",
                          "maxLength": 1000,
                          "minLength": 1
                        }
                      },
                      "additionalProperties": false
                    }
                  },
                  "data_format": {
                    "description": "The format of the messages in the Kafka topics. Determines how ClickHouse parses and serializes the data (e.g., JSON, CSV, Avro).",
                    "type": "string",
                    "enum": [
                      "Avro",
                      "AvroConfluent",
                      "CSV",
                      "JSONAsString",
                      "JSONCompactEachRow",
                      "JSONCompactStringsEachRow",
                      "JSONEachRow",
                      "JSONStringsEachRow",
                      "MsgPack",
                      "Parquet",
                      "RawBLOB",
                      "TSKV",
                      "TSV",
                      "TabSeparated"
                    ]
                  },
                  "date_time_input_format": {
                    "description": "Specifies how ClickHouse should parse DateTime values from text-based input formats. 'basic' uses simple parsing, 'best_effort' attempts more flexible parsing.",
                    "type": "string",
                    "enum": [
                      "basic",
                      "best_effort",
                      "best_effort_us"
                    ]
                  },
                  "group_name": {
                    "description": "The Kafka consumer group name. Multiple consumers with the same group name will share the workload and maintain offset positions.",
                    "type": "string",
                    "maxLength": 249,
                    "minLength": 1
                  },
                  "handle_error_mode": {
                    "description": "Defines how ClickHouse should handle errors when processing Kafka messages. 'default' stops on errors, 'stream' continues processing and logs errors.",
                    "type": "string",
                    "enum": [
                      "default",
                      "stream"
                    ]
                  },
                  "max_block_size": {
                    "description": "Maximum number of rows to collect before flushing data between Kafka and ClickHouse.",
                    "type": "integer",
                    "maximum": 1000000000,
                    "minimum": 0
                  },
                  "max_rows_per_message": {
                    "description": "Maximum number of rows that can be processed from a single Kafka message for row-based formats. Useful for controlling memory usage.",
                    "type": "integer",
                    "maximum": 1000000000,
                    "minimum": 1
                  },
                  "name": {
                    "description": "The name of the ClickHouse table to be created. This table can consume data from and write data to the specified Kafka topics.",
                    "type": "string",
                    "maxLength": 40,
                    "minLength": 1
                  },
                  "num_consumers": {
                    "description": "Number of Kafka consumers to run per table per replica. Increasing this can improve throughput but may increase resource usage.",
                    "type": "integer",
                    "maximum": 10,
                    "minimum": 1
                  },
                  "poll_max_batch_size": {
                    "description": "Maximum number of messages to fetch in a single Kafka poll operation for reading.",
                    "type": "integer",
                    "maximum": 1000000000,
                    "minimum": 0
                  },
                  "poll_max_timeout_ms": {
                    "description": "Timeout in milliseconds for a single poll from Kafka. Takes the value of the stream_flush_interval_ms server setting by default (500ms).",
                    "type": "integer",
                    "maximum": 30000,
                    "minimum": 0
                  },
                  "producer_batch_num_messages": {
                    "description": "The maximum number of messages in a batch sent to Kafka. If the number of messages exceeds this value, the batch is sent.",
                    "type": "integer",
                    "maximum": 1000000,
                    "minimum": 1
                  },
                  "producer_batch_size": {
                    "description": "The maximum size in bytes of a batch of messages sent to Kafka. If the batch size is exceeded, the batch is sent.",
                    "type": "integer",
                    "maximum": 2147483647,
                    "minimum": 0
                  },
                  "producer_compression_codec": {
                    "description": "The compression codec to use when sending a batch of messages to Kafka.",
                    "type": "string",
                    "enum": [
                      "gzip",
                      "lz4",
                      "none",
                      "snappy",
                      "zstd"
                    ]
                  },
                  "producer_compression_level": {
                    "description": "The compression level to use when sending a batch of messages to Kafka. Usable range is algorithm-dependent: [0-9] for gzip; [0-12] for lz4; only 0 for snappy; -1 = codec-dependent default compression level.",
                    "type": "integer",
                    "maximum": 12,
                    "minimum": -1
                  },
                  "producer_linger_ms": {
                    "description": "The time in milliseconds to wait for additional messages before sending a batch. If the time is exceeded, the batch is sent.",
                    "type": "integer",
                    "maximum": 900000,
                    "minimum": 0
                  },
                  "producer_queue_buffering_max_kbytes": {
                    "description": "The maximum size of the buffer in kilobytes before sending",
                    "type": "integer",
                    "maximum": 2147483647,
                    "minimum": 0
                  },
                  "producer_queue_buffering_max_messages": {
                    "description": "The maximum number of messages to buffer before sending",
                    "type": "integer",
                    "maximum": 2147483647,
                    "minimum": 0
                  },
                  "producer_request_required_acks": {
                    "description": "The number of acknowledgements the leader broker must receive from ISR brokers before responding to the request: 0=Broker does not send any response/ack to client, -1 will block until message is committed by all in sync replicas (ISRs).",
                    "type": "integer",
                    "maximum": 1000,
                    "minimum": -1
                  },
                  "skip_broken_messages": {
                    "description": "Number of broken messages to skip before stopping processing when reading from Kafka. Useful for handling corrupted data without failing the entire integration.",
                    "type": "integer",
                    "maximum": 1000000000,
                    "minimum": 0
                  },
                  "thread_per_consumer": {
                    "description": "When enabled, each consumer runs in its own thread, providing better isolation and potentially better performance for high-throughput scenarios.",
                    "type": "boolean"
                  },
                  "topics": {
                    "description": "Array of Kafka topics that this table will read data from or write data to. Messages from all specified topics will be inserted into this table, and data inserted into this table will be published to the topics.",
                    "type": "array",
                    "maxItems": 100,
                    "items": {
                      "description": "Kafka topic",
                      "type": "object",
                      "required": [
                        "name"
                      ],
                      "properties": {
                        "name": {
                          "description": "The name of the Kafka topic to read messages from or write messages to. The topic must exist in the Kafka cluster.",
                          "type": "string",
                          "maxLength": 249,
                          "minLength": 1
                        }
                      },
                      "additionalProperties": false
                    }
                  }
                },
                "additionalProperties": false
              }
            }
          },
          "additionalProperties": false
        },
        "clickhousePostgresql": {
          "description": "Clickhouse PostgreSQL configuration values",
          "type": "object",
          "properties": {
            "databases": {
              "description": "Databases to expose",
              "type": "array",
              "maxItems": 10,
              "items": {
                "description": "Database to expose",
                "type": "object",
                "properties": {
                  "database": {
                    "description": "PostgreSQL database to expose",
                    "type": "string",
                    "maxLength": 63,
                    "minLength": 1
                  },
                  "schema": {
                    "description": "PostgreSQL schema to expose",
                    "type": "string",
                    "maxLength": 63,
                    "minLength": 1
                  }
                },
                "additionalProperties": false
              }
            }
          },
          "additionalProperties": false
        },
        "datadog": {
          "description": "Datadog specific user configuration options",
          "type": "object",
          "properties": {
            "datadog_dbm_enabled": {
              "description": "Enable Datadog Database Monitoring",
              "type": "boolean"
            },
            "datadog_pgbouncer_enabled": {
              "description": "Enable Datadog PgBouncer Metric Tracking",
              "type": "boolean"
            },
            "datadog_tags": {
              "description": "Custom tags provided by user",
              "type": "array",
              "maxItems": 32,
              "items": {
                "description": "Datadog tag defined by user",
                "type": "object",
                "required": [
                  "tag"
                ],
                "properties": {
                  "comment": {
                    "description": "Optional tag explanation",
                    "type": "string",
                    "maxLength": 1024
                  },
                  "tag": {
                    "description": "Tag format and usage are described here: https://docs.datadoghq.com/getting_started/tagging. Tags with prefix 'aiven-' are reserved for Aiven.",
                    "type": "string",
                    "maxLength": 200,
                    "minLength": 1
                  }
                },
                "additionalProperties": false
              }
            },
            "exclude_consumer_groups": {
              "description": "List of custom metrics",
              "type": "array",
              "maxItems": 1024,
              "items": {
                "type": "string"
              }
            },
            "exclude_topics": {
              "description": "List of topics to exclude",
              "type": "array",
              "maxItems": 1024,
              "items": {
                "type": "string"
              }
            },
            "include_consumer_groups": {
              "description": "List of custom metrics",
              "type": "array",
              "maxItems": 1024,
              "items": {
                "type": "string"
              }
            },
            "include_topics": {
              "description": "List of topics to include",
              "type": "array",
              "maxItems": 1024,
              "items": {
                "type": "string"
              }
            },
            "kafka_custom_metrics": {
              "description": "List of custom metrics",
              "type": "array",
              "maxItems": 1024,
              "items": {
                "type": "string"
              }
            },
            "max_jmx_metrics": {
              "description": "Maximum number of JMX metrics to send",
              "type": "integer",
              "maximum": 100000,
              "minimum": 10
            },
            "mirrormaker_custom_metrics": {
              "description": "List of custom metrics",
              "type": "array",
              "maxItems": 1024,
              "items": {
                "type": "string"
              }
            },
            "opensearch": {
              "description": "Datadog Opensearch Options",
              "type": "object",
              "properties": {
                "cluster_stats_enabled": {
                  "description": "Enable Datadog Opensearch Cluster Monitoring",
                  "type": "boolean"
                },
                "index_stats_enabled": {
                  "description": "Enable Datadog Opensearch Index Monitoring",
                  "type": "boolean"
                },
                "pending_task_stats_enabled": {
                  "description": "Enable Datadog Opensearch Pending Task Monitoring",
                  "type": "boolean"
                },
                "pshard_stats_enabled": {
                  "description": "Enable Datadog Opensearch Primary Shard Monitoring",
                  "type": "boolean"
                }
              },
              "additionalProperties": false
            },
            "redis": {
              "description": "Datadog Redis Options",
              "type": "object",
              "properties": {
                "command_stats_enabled": {
                  "description": "Enable command_stats option in the agent's configuration",
                  "type": "boolean"
                }
              },
              "additionalProperties": false
            }
          },
          "additionalProperties": false
        },
        "destinationEndpointId": {
          "description": "Destination endpoint for the integration (if any)",
          "type": "string",
          "maxLength": 36,
          "x-kubernetes-validations": [
            {
              "rule": "self == oldSelf",
              "message": "Value is immutable"
            }
          ]
        },
        "destinationProjectName": {
          "description": "Destination project for the integration (if any)",
          "type": "string",
          "maxLength": 63,
          "x-kubernetes-validations": [
            {
              "rule": "self == oldSelf",
              "message": "Value is immutable"
            }
          ]
        },
        "destinationServiceName": {
          "description": "Destination service for the integration (if any)",
          "type": "string",
          "maxLength": 64,
          "x-kubernetes-validations": [
            {
              "rule": "self == oldSelf",
              "message": "Value is immutable"
            }
          ]
        },
        "externalAWSCloudwatchMetrics": {
          "description": "External AWS CloudWatch Metrics integration Logs configuration values",
          "type": "object",
          "properties": {
            "dropped_metrics": {
              "description": "Metrics to not send to AWS CloudWatch (takes precedence over extra_metrics)",
              "type": "array",
              "maxItems": 1024,
              "items": {
                "description": "Metric name and subfield",
                "type": "object",
                "required": [
                  "field",
                  "metric"
                ],
                "properties": {
                  "field": {
                    "description": "Identifier of a value in the metric",
                    "type": "string",
                    "maxLength": 1000
                  },
                  "metric": {
                    "description": "Identifier of the metric",
                    "type": "string",
                    "maxLength": 1000
                  }
                },
                "additionalProperties": false
              }
            },
            "extra_metrics": {
              "description": "Metrics to allow through to AWS CloudWatch (in addition to default metrics)",
              "type": "array",
              "maxItems": 1024,
              "items": {
                "description": "Metric name and subfield",
                "type": "object",
                "required": [
                  "field",
                  "metric"
                ],
                "properties": {
                  "field": {
                    "description": "Identifier of a value in the metric",
                    "type": "string",
                    "maxLength": 1000
                  },
                  "metric": {
                    "description": "Identifier of the metric",
                    "type": "string",
                    "maxLength": 1000
                  }
                },
                "additionalProperties": false
              }
            }
          },
          "additionalProperties": false
        },
        "integrationType": {
          "description": "Type of the service integration accepted by Aiven API. Some values may not be supported by the operator",
          "type": "string",
          "enum": [
            "alertmanager",
            "autoscaler",
            "caching",
            "cassandra_cross_service_cluster",
            "clickhouse_kafka",
            "clickhouse_postgresql",
            "dashboard",
            "datadog",
            "datasource",
            "external_aws_cloudwatch_logs",
            "external_aws_cloudwatch_metrics",
            "external_elasticsearch_logs",
            "external_google_cloud_logging",
            "external_opensearch_logs",
            "flink",
            "flink_external_kafka",
            "flink_external_postgresql",
            "internal_connectivity",
            "jolokia",
            "kafka_connect",
            "kafka_logs",
            "kafka_mirrormaker",
            "logs",
            "m3aggregator",
            "m3coordinator",
            "metrics",
            "opensearch_cross_cluster_replication",
            "opensearch_cross_cluster_search",
            "prometheus",
            "read_replica",
            "rsyslog",
            "schema_registry_proxy",
            "stresstester",
            "thanosquery",
            "thanosstore",
            "vmalert"
          ],
          "x-kubernetes-validations": [
            {
              "rule": "self == oldSelf",
              "message": "Value is immutable"
            }
          ]
        },
        "kafkaConnect": {
          "description": "Kafka Connect service configuration values",
          "type": "object",
          "properties": {
            "kafka_connect": {
              "description": "Kafka Connect service configuration values",
              "type": "object",
              "properties": {
                "config_storage_topic": {
                  "description": "The name of the topic where connector and task configuration data are stored.This must be the same for all workers with the same group_id.",
                  "type": "string",
                  "maxLength": 249
                },
                "group_id": {
                  "description": "A unique string that identifies the Connect cluster group this worker belongs to.",
                  "type": "string",
                  "maxLength": 249
                },
                "offset_storage_topic": {
                  "description": "The name of the topic where connector and task configuration offsets are stored.This must be the same for all workers with the same group_id.",
                  "type": "string",
                  "maxLength": 249
                },
                "status_storage_topic": {
                  "description": "The name of the topic where connector and task configuration status updates are stored.This must be the same for all workers with the same group_id.",
                  "type": "string",
                  "maxLength": 249
                }
              },
              "additionalProperties": false
            }
          },
          "additionalProperties": false
        },
        "kafkaLogs": {
          "description": "Kafka logs configuration values",
          "type": "object",
          "required": [
            "kafka_topic"
          ],
          "properties": {
            "kafka_topic": {
              "description": "Topic name",
              "type": "string",
              "maxLength": 249,
              "minLength": 1
            },
            "selected_log_fields": {
              "description": "The list of logging fields that will be sent to the integration logging service. The MESSAGE and timestamp fields are always sent.",
              "type": "array",
              "maxItems": 5,
              "items": {
                "type": "string"
              }
            }
          },
          "additionalProperties": false
        },
        "kafkaMirrormaker": {
          "description": "Kafka MirrorMaker configuration values",
          "type": "object",
          "properties": {
            "cluster_alias": {
              "description": "The alias under which the Kafka cluster is known to MirrorMaker. Can contain the following symbols: ASCII alphanumerics, '.', '_', and '-'.",
              "type": "string",
              "maxLength": 128,
              "pattern": "^[a-zA-Z0-9_.-]+$"
            },
            "kafka_mirrormaker": {
              "description": "Kafka MirrorMaker configuration values",
              "type": "object",
              "properties": {
                "consumer_auto_offset_reset": {
                  "description": "Set where consumer starts to consume data. Value `earliest`: Start replication from the earliest offset. Value `latest`: Start replication from the latest offset. Default is `earliest`.",
                  "type": "string",
                  "enum": [
                    "earliest",
                    "latest"
                  ]
                },
                "consumer_fetch_min_bytes": {
                  "description": "The minimum amount of data the server should return for a fetch request",
                  "type": "integer",
                  "maximum": 5242880,
                  "minimum": 1
                },
                "consumer_max_poll_records": {
                  "description": "Set consumer max.poll.records. The default is 500.",
                  "type": "integer",
                  "maximum": 20000,
                  "minimum": 100
                },
                "producer_batch_size": {
                  "description": "The batch size in bytes producer will attempt to collect before publishing to broker.",
                  "type": "integer",
                  "maximum": 5242880,
                  "minimum": 0
                },
                "producer_buffer_memory": {
                  "description": "The amount of bytes producer can use for buffering data before publishing to broker.",
                  "type": "integer",
                  "maximum": 134217728,
                  "minimum": 5242880
                },
                "producer_compression_type": {
                  "description": "Specify the default compression type for producers. This configuration accepts the standard compression codecs ('gzip', 'snappy', 'lz4', 'zstd'). It additionally accepts 'none' which is the default and equivalent to no compression.",
                  "type": "string",
                  "enum": [
                    "gzip",
                    "lz4",
                    "none",
                    "snappy",
                    "zstd"
                  ]
                },
                "producer_linger_ms": {
                  "description": "The linger time (ms) for waiting new data to arrive for publishing.",
                  "type": "integer",
                  "maximum": 5000,
                  "minimum": 0
                },
                "producer_max_request_size": {
                  "description": "The maximum request size in bytes.",
                  "type": "integer",
                  "maximum": 268435456,
                  "minimum": 0
                }
              },
              "additionalProperties": false
            }
          },
          "additionalProperties": false
        },
        "logs": {
          "description": "Logs configuration values",
          "type": "object",
          "properties": {
            "elasticsearch_index_days_max": {
              "description": "Elasticsearch index retention limit",
              "type": "integer",
              "maximum": 10000,
              "minimum": 1
            },
            "elasticsearch_index_prefix": {
              "description": "Elasticsearch index prefix",
              "type": "string",
              "maxLength": 1024,
              "minLength": 1,
              "pattern": "^[a-z0-9][a-z0-9-_.]+$"
            },
            "selected_log_fields": {
              "description": "The list of logging fields that will be sent to the integration logging service. The MESSAGE and timestamp fields are always sent.",
              "type": "array",
              "maxItems": 5,
              "items": {
                "type": "string"
              }
            }
          },
          "additionalProperties": false
        },
        "metrics": {
          "description": "Metrics configuration values",
          "type": "object",
          "properties": {
            "database": {
              "description": "Name of the database where to store metric datapoints. Only affects PostgreSQL destinations. Defaults to 'metrics'. Note that this must be the same for all metrics integrations that write data to the same PostgreSQL service.",
              "type": "string",
              "maxLength": 40,
              "pattern": "^[_A-Za-z0-9][-_A-Za-z0-9]{0,39}$"
            },
            "retention_days": {
              "description": "Number of days to keep old metrics. Only affects PostgreSQL destinations. Set to 0 for no automatic cleanup. Defaults to 30 days.",
              "type": "integer",
              "maximum": 10000,
              "minimum": 0
            },
            "ro_username": {
              "description": "Name of a user that can be used to read metrics. This will be used for Grafana integration (if enabled) to prevent Grafana users from making undesired changes. Only affects PostgreSQL destinations. Defaults to 'metrics_reader'. Note that this must be the same for all metrics integrations that write data to the same PostgreSQL service.",
              "type": "string",
              "maxLength": 40,
              "pattern": "^[_A-Za-z0-9][-._A-Za-z0-9]{0,39}$"
            },
            "source_mysql": {
              "description": "Configuration options for metrics where source service is MySQL",
              "type": "object",
              "properties": {
                "telegraf": {
                  "description": "Configuration options for Telegraf MySQL input plugin",
                  "type": "object",
                  "properties": {
                    "gather_event_waits": {
                      "description": "Gather metrics from PERFORMANCE_SCHEMA.EVENT_WAITS",
                      "type": "boolean"
                    },
                    "gather_file_events_stats": {
                      "description": "gather metrics from PERFORMANCE_SCHEMA.FILE_SUMMARY_BY_EVENT_NAME",
                      "type": "boolean"
                    },
                    "gather_index_io_waits": {
                      "description": "Gather metrics from PERFORMANCE_SCHEMA.TABLE_IO_WAITS_SUMMARY_BY_INDEX_USAGE",
                      "type": "boolean"
                    },
                    "gather_info_schema_auto_inc": {
                      "description": "Gather auto_increment columns and max values from information schema",
                      "type": "boolean"
                    },
                    "gather_innodb_metrics": {
                      "description": "Gather metrics from INFORMATION_SCHEMA.INNODB_METRICS",
                      "type": "boolean"
                    },
                    "gather_perf_events_statements": {
                      "description": "Gather metrics from PERFORMANCE_SCHEMA.EVENTS_STATEMENTS_SUMMARY_BY_DIGEST",
                      "type": "boolean"
                    },
                    "gather_process_list": {
                      "description": "Gather thread state counts from INFORMATION_SCHEMA.PROCESSLIST",
                      "type": "boolean"
                    },
                    "gather_slave_status": {
                      "description": "Gather metrics from SHOW SLAVE STATUS command output",
                      "type": "boolean"
                    },
                    "gather_table_io_waits": {
                      "description": "Gather metrics from PERFORMANCE_SCHEMA.TABLE_IO_WAITS_SUMMARY_BY_TABLE",
                      "type": "boolean"
                    },
                    "gather_table_lock_waits": {
                      "description": "Gather metrics from PERFORMANCE_SCHEMA.TABLE_LOCK_WAITS",
                      "type": "boolean"
                    },
                    "gather_table_schema": {
                      "description": "Gather metrics from INFORMATION_SCHEMA.TABLES",
                      "type": "boolean"
                    },
                    "perf_events_statements_digest_text_limit": {
                      "description": "Truncates digest text from perf_events_statements into this many characters",
                      "type": "integer",
                      "maximum": 2048,
                      "minimum": 1
                    },
                    "perf_events_statements_limit": {
                      "description": "Limits metrics from perf_events_statements",
                      "type": "integer",
                      "maximum": 4000,
                      "minimum": 1
                    },
                    "perf_events_statements_time_limit": {
                      "description": "Only include perf_events_statements whose last seen is less than this many seconds",
                      "type": "integer",
                      "maximum": 2592000,
                      "minimum": 1
                    }
                  },
                  "additionalProperties": false
                }
              },
              "additionalProperties": false
            },
            "username": {
              "description": "Name of the user used to write metrics. Only affects PostgreSQL destinations. Defaults to 'metrics_writer'. Note that this must be the same for all metrics integrations that write data to the same PostgreSQL service.",
              "type": "string",
              "maxLength": 40,
              "pattern": "^[_A-Za-z0-9][-._A-Za-z0-9]{0,39}$"
            }
          },
          "additionalProperties": false
        },
        "project": {
          "description": "Identifies the project this resource belongs to",
          "type": "string",
          "maxLength": 63,
          "pattern": "^[a-zA-Z0-9_-]+$",
          "x-kubernetes-validations": [
            {
              "rule": "self == oldSelf",
              "message": "Value is immutable"
            }
          ]
        },
        "sourceEndpointID": {
          "description": "Source endpoint for the integration (if any)",
          "type": "string",
          "maxLength": 36,
          "x-kubernetes-validations": [
            {
              "rule": "self == oldSelf",
              "message": "Value is immutable"
            }
          ]
        },
        "sourceProjectName": {
          "description": "Source project for the integration (if any)",
          "type": "string",
          "maxLength": 63,
          "x-kubernetes-validations": [
            {
              "rule": "self == oldSelf",
              "message": "Value is immutable"
            }
          ]
        },
        "sourceServiceName": {
          "description": "Source service for the integration (if any)",
          "type": "string",
          "maxLength": 64,
          "x-kubernetes-validations": [
            {
              "rule": "self == oldSelf",
              "message": "Value is immutable"
            }
          ]
        }
      },
      "additionalProperties": false
    },
    "status": {
      "description": "ServiceIntegrationStatus defines the observed state of ServiceIntegration",
      "type": "object",
      "required": [
        "conditions",
        "id"
      ],
      "properties": {
        "conditions": {
          "description": "Conditions represent the latest available observations of an ServiceIntegration state",
          "type": "array",
          "items": {
            "description": "Condition contains details for one aspect of the current state of this API Resource.",
            "type": "object",
            "required": [
              "lastTransitionTime",
              "message",
              "reason",
              "status",
              "type"
            ],
            "properties": {
              "lastTransitionTime": {
                "description": "lastTransitionTime is the last time the condition transitioned from one status to another.\nThis should be when the underlying condition changed.  If that is not known, then using the time when the API field changed is acceptable.",
                "type": "string",
                "format": "date-time"
              },
              "message": {
                "description": "message is a human readable message indicating details about the transition.\nThis may be an empty string.",
                "type": "string",
                "maxLength": 32768
              },
              "observedGeneration": {
                "description": "observedGeneration represents the .metadata.generation that the condition was set based upon.\nFor instance, if .metadata.generation is currently 12, but the .status.conditions[x].observedGeneration is 9, the condition is out of date\nwith respect to the current state of the instance.",
                "type": "integer",
                "format": "int64",
                "minimum": 0
              },
              "reason": {
                "description": "reason contains a programmatic identifier indicating the reason for the condition's last transition.\nProducers of specific condition types may define expected values and meanings for this field,\nand whether the values are considered a guaranteed API.\nThe value should be a CamelCase string.\nThis field may not be empty.",
                "type": "string",
                "maxLength": 1024,
                "minLength": 1,
                "pattern": "^[A-Za-z]([A-Za-z0-9_,:]*[A-Za-z0-9_])?$"
              },
              "status": {
                "description": "status of the condition, one of True, False, Unknown.",
                "type": "string",
                "enum": [
                  "True",
                  "False",
                  "Unknown"
                ]
              },
              "type": {
                "description": "type of condition in CamelCase or in foo.example.com/CamelCase.",
                "type": "string",
                "maxLength": 316,
                "pattern": "^([a-z0-9]([-a-z0-9]*[a-z0-9])?(\\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*/)?(([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9])$"
              }
            },
            "additionalProperties": false
          }
        },
        "id": {
          "description": "Service integration ID",
          "type": "string"
        }
      },
      "additionalProperties": false
    }
  }
}
