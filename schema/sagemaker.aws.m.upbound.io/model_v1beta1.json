{
  "description": "Model is the Schema for the Models API. Provides a SageMaker AI model resource.",
  "type": "object",
  "required": [
    "spec"
  ],
  "properties": {
    "apiVersion": {
      "description": "APIVersion defines the versioned schema of this representation of an object.\nServers should convert recognized schemas to the latest internal value, and\nmay reject unrecognized values.\nMore info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources",
      "type": "string"
    },
    "kind": {
      "description": "Kind is a string value representing the REST resource this object represents.\nServers may infer this from the endpoint the client submits requests to.\nCannot be updated.\nIn CamelCase.\nMore info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds",
      "type": "string"
    },
    "metadata": {
      "type": "object"
    },
    "spec": {
      "description": "ModelSpec defines the desired state of Model",
      "type": "object",
      "required": [
        "forProvider"
      ],
      "properties": {
        "forProvider": {
          "type": "object",
          "required": [
            "region"
          ],
          "properties": {
            "container": {
              "description": "Specifies containers in the inference pipeline. If not specified, the primary_container argument is required. Fields are documented below.",
              "type": "array",
              "items": {
                "type": "object",
                "properties": {
                  "containerHostname": {
                    "description": "The DNS host name for the container.",
                    "type": "string"
                  },
                  "environment": {
                    "description": "Environment variables for the Docker container.\nA list of key value pairs.",
                    "type": "object",
                    "additionalProperties": {
                      "type": "string"
                    },
                    "x-kubernetes-map-type": "granular"
                  },
                  "image": {
                    "description": "The registry path where the inference code image is stored in Amazon ECR.",
                    "type": "string"
                  },
                  "imageConfig": {
                    "description": "Specifies whether the model container is in Amazon ECR or a private Docker registry accessible from your Amazon Virtual Private Cloud (VPC). For more information see Using a Private Docker Registry for Real-Time Inference Containers. see Image Config.",
                    "type": "object",
                    "properties": {
                      "repositoryAccessMode": {
                        "description": "Specifies whether the model container is in Amazon ECR or a private Docker registry accessible from your Amazon Virtual Private Cloud (VPC). Allowed values are: Platform and Vpc.",
                        "type": "string"
                      },
                      "repositoryAuthConfig": {
                        "description": "Specifies an authentication configuration for the private docker registry where your model image is hosted. Specify a value for this property only if you specified Vpc as the value for the RepositoryAccessMode field, and the private Docker registry where the model image is hosted requires authentication. see Repository Auth Config.",
                        "type": "object",
                        "properties": {
                          "repositoryCredentialsProviderArn": {
                            "description": "The Amazon Resource Name (ARN) of an AWS Lambda function that provides credentials to authenticate to the private Docker registry where your model image is hosted. For information about how to create an AWS Lambda function, see Create a Lambda function with the console in the AWS Lambda Developer Guide.",
                            "type": "string"
                          }
                        },
                        "additionalProperties": false
                      }
                    },
                    "additionalProperties": false
                  },
                  "inferenceSpecificationName": {
                    "description": "The inference specification name in the model package version.",
                    "type": "string"
                  },
                  "mode": {
                    "description": "The container hosts value SingleModel/MultiModel. The default value is SingleModel.",
                    "type": "string"
                  },
                  "modelDataSource": {
                    "description": "The location of model data to deploy. Use this for uncompressed model deployment. For information about how to deploy an uncompressed model, see Deploying uncompressed models in the AWS SageMaker AI Developer Guide.",
                    "type": "object",
                    "properties": {
                      "s3DataSource": {
                        "description": "The S3 location of model data to deploy.",
                        "type": "array",
                        "items": {
                          "type": "object",
                          "properties": {
                            "compressionType": {
                              "description": "How the model data is prepared. Allowed values are: None and Gzip.",
                              "type": "string"
                            },
                            "modelAccessConfig": {
                              "description": "Specifies the access configuration file for the ML model. You can explicitly accept the model end-user license agreement (EULA) within the [model_access_config configuration block]. see Model Access Config.",
                              "type": "object",
                              "properties": {
                                "acceptEula": {
                                  "description": "Specifies agreement to the model end-user license agreement (EULA). The AcceptEula value must be explicitly defined as true in order to accept the EULA that this model requires. You are responsible for reviewing and complying with any applicable license terms and making sure they are acceptable for your use case before downloading or using a model.",
                                  "type": "boolean"
                                }
                              },
                              "additionalProperties": false
                            },
                            "s3DataType": {
                              "description": "The type of model data to deploy. Allowed values are: S3Object and S3Prefix.",
                              "type": "string"
                            },
                            "s3Uri": {
                              "description": "The S3 path of model data to deploy.",
                              "type": "string"
                            }
                          },
                          "additionalProperties": false
                        }
                      }
                    },
                    "additionalProperties": false
                  },
                  "modelDataUrl": {
                    "description": "The URL for the S3 location where model artifacts are stored.",
                    "type": "string"
                  },
                  "modelPackageName": {
                    "description": "The Amazon Resource Name (ARN) of the model package to use to create the model.",
                    "type": "string"
                  },
                  "multiModelConfig": {
                    "description": "Specifies additional configuration for multi-model endpoints. see Multi Model Config.",
                    "type": "object",
                    "properties": {
                      "modelCacheSetting": {
                        "description": "Whether to cache models for a multi-model endpoint. By default, multi-model endpoints cache models so that a model does not have to be loaded into memory each time it is invoked. Some use cases do not benefit from model caching. For example, if an endpoint hosts a large number of models that are each invoked infrequently, the endpoint might perform better if you disable model caching. To disable model caching, set the value of this parameter to Disabled. Allowed values are: Enabled and Disabled.",
                        "type": "string"
                      }
                    },
                    "additionalProperties": false
                  }
                },
                "additionalProperties": false
              }
            },
            "enableNetworkIsolation": {
              "description": "Isolates the model container. No inbound or outbound network calls can be made to or from the model container.",
              "type": "boolean"
            },
            "executionRoleArn": {
              "description": "A role that SageMaker AI can assume to access model artifacts and docker images for deployment.",
              "type": "string"
            },
            "executionRoleArnRef": {
              "description": "Reference to a Role in iam to populate executionRoleArn.",
              "type": "object",
              "required": [
                "name"
              ],
              "properties": {
                "name": {
                  "description": "Name of the referenced object.",
                  "type": "string"
                },
                "namespace": {
                  "description": "Namespace of the referenced object",
                  "type": "string"
                },
                "policy": {
                  "description": "Policies for referencing.",
                  "type": "object",
                  "properties": {
                    "resolution": {
                      "description": "Resolution specifies whether resolution of this reference is required.\nThe default is 'Required', which means the reconcile will fail if the\nreference cannot be resolved. 'Optional' means this reference will be\na no-op if it cannot be resolved.",
                      "type": "string",
                      "default": "Required",
                      "enum": [
                        "Required",
                        "Optional"
                      ]
                    },
                    "resolve": {
                      "description": "Resolve specifies when this reference should be resolved. The default\nis 'IfNotPresent', which will attempt to resolve the reference only when\nthe corresponding field is not present. Use 'Always' to resolve the\nreference on every reconcile.",
                      "type": "string",
                      "enum": [
                        "Always",
                        "IfNotPresent"
                      ]
                    }
                  },
                  "additionalProperties": false
                }
              },
              "additionalProperties": false
            },
            "executionRoleArnSelector": {
              "description": "Selector for a Role in iam to populate executionRoleArn.",
              "type": "object",
              "properties": {
                "matchControllerRef": {
                  "description": "MatchControllerRef ensures an object with the same controller reference\nas the selecting object is selected.",
                  "type": "boolean"
                },
                "matchLabels": {
                  "description": "MatchLabels ensures an object with matching labels is selected.",
                  "type": "object",
                  "additionalProperties": {
                    "type": "string"
                  }
                },
                "namespace": {
                  "description": "Namespace for the selector",
                  "type": "string"
                },
                "policy": {
                  "description": "Policies for selection.",
                  "type": "object",
                  "properties": {
                    "resolution": {
                      "description": "Resolution specifies whether resolution of this reference is required.\nThe default is 'Required', which means the reconcile will fail if the\nreference cannot be resolved. 'Optional' means this reference will be\na no-op if it cannot be resolved.",
                      "type": "string",
                      "default": "Required",
                      "enum": [
                        "Required",
                        "Optional"
                      ]
                    },
                    "resolve": {
                      "description": "Resolve specifies when this reference should be resolved. The default\nis 'IfNotPresent', which will attempt to resolve the reference only when\nthe corresponding field is not present. Use 'Always' to resolve the\nreference on every reconcile.",
                      "type": "string",
                      "enum": [
                        "Always",
                        "IfNotPresent"
                      ]
                    }
                  },
                  "additionalProperties": false
                }
              },
              "additionalProperties": false
            },
            "inferenceExecutionConfig": {
              "description": "Specifies details of how containers in a multi-container endpoint are called. see Inference Execution Config.",
              "type": "object",
              "properties": {
                "mode": {
                  "description": "The container hosts value SingleModel/MultiModel. The default value is SingleModel.",
                  "type": "string"
                }
              },
              "additionalProperties": false
            },
            "primaryContainer": {
              "description": "The primary docker image containing inference code that is used when the model is deployed for predictions.  If not specified, the container argument is required. Fields are documented below.",
              "type": "object",
              "properties": {
                "containerHostname": {
                  "description": "The DNS host name for the container.",
                  "type": "string"
                },
                "environment": {
                  "description": "Environment variables for the Docker container.\nA list of key value pairs.",
                  "type": "object",
                  "additionalProperties": {
                    "type": "string"
                  },
                  "x-kubernetes-map-type": "granular"
                },
                "image": {
                  "description": "The registry path where the inference code image is stored in Amazon ECR.",
                  "type": "string"
                },
                "imageConfig": {
                  "description": "Specifies whether the model container is in Amazon ECR or a private Docker registry accessible from your Amazon Virtual Private Cloud (VPC). For more information see Using a Private Docker Registry for Real-Time Inference Containers. see Image Config.",
                  "type": "object",
                  "properties": {
                    "repositoryAccessMode": {
                      "description": "Specifies whether the model container is in Amazon ECR or a private Docker registry accessible from your Amazon Virtual Private Cloud (VPC). Allowed values are: Platform and Vpc.",
                      "type": "string"
                    },
                    "repositoryAuthConfig": {
                      "description": "Specifies an authentication configuration for the private docker registry where your model image is hosted. Specify a value for this property only if you specified Vpc as the value for the RepositoryAccessMode field, and the private Docker registry where the model image is hosted requires authentication. see Repository Auth Config.",
                      "type": "object",
                      "properties": {
                        "repositoryCredentialsProviderArn": {
                          "description": "The Amazon Resource Name (ARN) of an AWS Lambda function that provides credentials to authenticate to the private Docker registry where your model image is hosted. For information about how to create an AWS Lambda function, see Create a Lambda function with the console in the AWS Lambda Developer Guide.",
                          "type": "string"
                        }
                      },
                      "additionalProperties": false
                    }
                  },
                  "additionalProperties": false
                },
                "inferenceSpecificationName": {
                  "description": "The inference specification name in the model package version.",
                  "type": "string"
                },
                "mode": {
                  "description": "The container hosts value SingleModel/MultiModel. The default value is SingleModel.",
                  "type": "string"
                },
                "modelDataSource": {
                  "description": "The location of model data to deploy. Use this for uncompressed model deployment. For information about how to deploy an uncompressed model, see Deploying uncompressed models in the AWS SageMaker AI Developer Guide.",
                  "type": "object",
                  "properties": {
                    "s3DataSource": {
                      "description": "The S3 location of model data to deploy.",
                      "type": "array",
                      "items": {
                        "type": "object",
                        "properties": {
                          "compressionType": {
                            "description": "How the model data is prepared. Allowed values are: None and Gzip.",
                            "type": "string"
                          },
                          "modelAccessConfig": {
                            "description": "Specifies the access configuration file for the ML model. You can explicitly accept the model end-user license agreement (EULA) within the [model_access_config configuration block]. see Model Access Config.",
                            "type": "object",
                            "properties": {
                              "acceptEula": {
                                "description": "Specifies agreement to the model end-user license agreement (EULA). The AcceptEula value must be explicitly defined as true in order to accept the EULA that this model requires. You are responsible for reviewing and complying with any applicable license terms and making sure they are acceptable for your use case before downloading or using a model.",
                                "type": "boolean"
                              }
                            },
                            "additionalProperties": false
                          },
                          "s3DataType": {
                            "description": "The type of model data to deploy. Allowed values are: S3Object and S3Prefix.",
                            "type": "string"
                          },
                          "s3Uri": {
                            "description": "The S3 path of model data to deploy.",
                            "type": "string"
                          }
                        },
                        "additionalProperties": false
                      }
                    }
                  },
                  "additionalProperties": false
                },
                "modelDataUrl": {
                  "description": "The URL for the S3 location where model artifacts are stored.",
                  "type": "string"
                },
                "modelPackageName": {
                  "description": "The Amazon Resource Name (ARN) of the model package to use to create the model.",
                  "type": "string"
                },
                "multiModelConfig": {
                  "description": "Specifies additional configuration for multi-model endpoints. see Multi Model Config.",
                  "type": "object",
                  "properties": {
                    "modelCacheSetting": {
                      "description": "Whether to cache models for a multi-model endpoint. By default, multi-model endpoints cache models so that a model does not have to be loaded into memory each time it is invoked. Some use cases do not benefit from model caching. For example, if an endpoint hosts a large number of models that are each invoked infrequently, the endpoint might perform better if you disable model caching. To disable model caching, set the value of this parameter to Disabled. Allowed values are: Enabled and Disabled.",
                      "type": "string"
                    }
                  },
                  "additionalProperties": false
                }
              },
              "additionalProperties": false
            },
            "region": {
              "description": "Region where this resource will be managed. Defaults to the Region set in the provider configuration.\nRegion is the region you'd like your resource to be created in.",
              "type": "string"
            },
            "tags": {
              "description": "Key-value map of resource tags.",
              "type": "object",
              "additionalProperties": {
                "type": "string"
              },
              "x-kubernetes-map-type": "granular"
            },
            "vpcConfig": {
              "description": "Specifies the VPC that you want your model to connect to. VpcConfig is used in hosting services and in batch transform.",
              "type": "object",
              "properties": {
                "securityGroupIds": {
                  "type": "array",
                  "items": {
                    "type": "string"
                  },
                  "x-kubernetes-list-type": "set"
                },
                "subnets": {
                  "type": "array",
                  "items": {
                    "type": "string"
                  },
                  "x-kubernetes-list-type": "set"
                }
              },
              "additionalProperties": false
            }
          },
          "additionalProperties": false
        },
        "initProvider": {
          "description": "THIS IS A BETA FIELD. It will be honored\nunless the Management Policies feature flag is disabled.\nInitProvider holds the same fields as ForProvider, with the exception\nof Identifier and other resource reference fields. The fields that are\nin InitProvider are merged into ForProvider when the resource is created.\nThe same fields are also added to the terraform ignore_changes hook, to\navoid updating them after creation. This is useful for fields that are\nrequired on creation, but we do not desire to update them after creation,\nfor example because of an external controller is managing them, like an\nautoscaler.",
          "type": "object",
          "properties": {
            "container": {
              "description": "Specifies containers in the inference pipeline. If not specified, the primary_container argument is required. Fields are documented below.",
              "type": "array",
              "items": {
                "type": "object",
                "properties": {
                  "containerHostname": {
                    "description": "The DNS host name for the container.",
                    "type": "string"
                  },
                  "environment": {
                    "description": "Environment variables for the Docker container.\nA list of key value pairs.",
                    "type": "object",
                    "additionalProperties": {
                      "type": "string"
                    },
                    "x-kubernetes-map-type": "granular"
                  },
                  "image": {
                    "description": "The registry path where the inference code image is stored in Amazon ECR.",
                    "type": "string"
                  },
                  "imageConfig": {
                    "description": "Specifies whether the model container is in Amazon ECR or a private Docker registry accessible from your Amazon Virtual Private Cloud (VPC). For more information see Using a Private Docker Registry for Real-Time Inference Containers. see Image Config.",
                    "type": "object",
                    "properties": {
                      "repositoryAccessMode": {
                        "description": "Specifies whether the model container is in Amazon ECR or a private Docker registry accessible from your Amazon Virtual Private Cloud (VPC). Allowed values are: Platform and Vpc.",
                        "type": "string"
                      },
                      "repositoryAuthConfig": {
                        "description": "Specifies an authentication configuration for the private docker registry where your model image is hosted. Specify a value for this property only if you specified Vpc as the value for the RepositoryAccessMode field, and the private Docker registry where the model image is hosted requires authentication. see Repository Auth Config.",
                        "type": "object",
                        "properties": {
                          "repositoryCredentialsProviderArn": {
                            "description": "The Amazon Resource Name (ARN) of an AWS Lambda function that provides credentials to authenticate to the private Docker registry where your model image is hosted. For information about how to create an AWS Lambda function, see Create a Lambda function with the console in the AWS Lambda Developer Guide.",
                            "type": "string"
                          }
                        },
                        "additionalProperties": false
                      }
                    },
                    "additionalProperties": false
                  },
                  "inferenceSpecificationName": {
                    "description": "The inference specification name in the model package version.",
                    "type": "string"
                  },
                  "mode": {
                    "description": "The container hosts value SingleModel/MultiModel. The default value is SingleModel.",
                    "type": "string"
                  },
                  "modelDataSource": {
                    "description": "The location of model data to deploy. Use this for uncompressed model deployment. For information about how to deploy an uncompressed model, see Deploying uncompressed models in the AWS SageMaker AI Developer Guide.",
                    "type": "object",
                    "properties": {
                      "s3DataSource": {
                        "description": "The S3 location of model data to deploy.",
                        "type": "array",
                        "items": {
                          "type": "object",
                          "properties": {
                            "compressionType": {
                              "description": "How the model data is prepared. Allowed values are: None and Gzip.",
                              "type": "string"
                            },
                            "modelAccessConfig": {
                              "description": "Specifies the access configuration file for the ML model. You can explicitly accept the model end-user license agreement (EULA) within the [model_access_config configuration block]. see Model Access Config.",
                              "type": "object",
                              "properties": {
                                "acceptEula": {
                                  "description": "Specifies agreement to the model end-user license agreement (EULA). The AcceptEula value must be explicitly defined as true in order to accept the EULA that this model requires. You are responsible for reviewing and complying with any applicable license terms and making sure they are acceptable for your use case before downloading or using a model.",
                                  "type": "boolean"
                                }
                              },
                              "additionalProperties": false
                            },
                            "s3DataType": {
                              "description": "The type of model data to deploy. Allowed values are: S3Object and S3Prefix.",
                              "type": "string"
                            },
                            "s3Uri": {
                              "description": "The S3 path of model data to deploy.",
                              "type": "string"
                            }
                          },
                          "additionalProperties": false
                        }
                      }
                    },
                    "additionalProperties": false
                  },
                  "modelDataUrl": {
                    "description": "The URL for the S3 location where model artifacts are stored.",
                    "type": "string"
                  },
                  "modelPackageName": {
                    "description": "The Amazon Resource Name (ARN) of the model package to use to create the model.",
                    "type": "string"
                  },
                  "multiModelConfig": {
                    "description": "Specifies additional configuration for multi-model endpoints. see Multi Model Config.",
                    "type": "object",
                    "properties": {
                      "modelCacheSetting": {
                        "description": "Whether to cache models for a multi-model endpoint. By default, multi-model endpoints cache models so that a model does not have to be loaded into memory each time it is invoked. Some use cases do not benefit from model caching. For example, if an endpoint hosts a large number of models that are each invoked infrequently, the endpoint might perform better if you disable model caching. To disable model caching, set the value of this parameter to Disabled. Allowed values are: Enabled and Disabled.",
                        "type": "string"
                      }
                    },
                    "additionalProperties": false
                  }
                },
                "additionalProperties": false
              }
            },
            "enableNetworkIsolation": {
              "description": "Isolates the model container. No inbound or outbound network calls can be made to or from the model container.",
              "type": "boolean"
            },
            "executionRoleArn": {
              "description": "A role that SageMaker AI can assume to access model artifacts and docker images for deployment.",
              "type": "string"
            },
            "executionRoleArnRef": {
              "description": "Reference to a Role in iam to populate executionRoleArn.",
              "type": "object",
              "required": [
                "name"
              ],
              "properties": {
                "name": {
                  "description": "Name of the referenced object.",
                  "type": "string"
                },
                "namespace": {
                  "description": "Namespace of the referenced object",
                  "type": "string"
                },
                "policy": {
                  "description": "Policies for referencing.",
                  "type": "object",
                  "properties": {
                    "resolution": {
                      "description": "Resolution specifies whether resolution of this reference is required.\nThe default is 'Required', which means the reconcile will fail if the\nreference cannot be resolved. 'Optional' means this reference will be\na no-op if it cannot be resolved.",
                      "type": "string",
                      "default": "Required",
                      "enum": [
                        "Required",
                        "Optional"
                      ]
                    },
                    "resolve": {
                      "description": "Resolve specifies when this reference should be resolved. The default\nis 'IfNotPresent', which will attempt to resolve the reference only when\nthe corresponding field is not present. Use 'Always' to resolve the\nreference on every reconcile.",
                      "type": "string",
                      "enum": [
                        "Always",
                        "IfNotPresent"
                      ]
                    }
                  },
                  "additionalProperties": false
                }
              },
              "additionalProperties": false
            },
            "executionRoleArnSelector": {
              "description": "Selector for a Role in iam to populate executionRoleArn.",
              "type": "object",
              "properties": {
                "matchControllerRef": {
                  "description": "MatchControllerRef ensures an object with the same controller reference\nas the selecting object is selected.",
                  "type": "boolean"
                },
                "matchLabels": {
                  "description": "MatchLabels ensures an object with matching labels is selected.",
                  "type": "object",
                  "additionalProperties": {
                    "type": "string"
                  }
                },
                "namespace": {
                  "description": "Namespace for the selector",
                  "type": "string"
                },
                "policy": {
                  "description": "Policies for selection.",
                  "type": "object",
                  "properties": {
                    "resolution": {
                      "description": "Resolution specifies whether resolution of this reference is required.\nThe default is 'Required', which means the reconcile will fail if the\nreference cannot be resolved. 'Optional' means this reference will be\na no-op if it cannot be resolved.",
                      "type": "string",
                      "default": "Required",
                      "enum": [
                        "Required",
                        "Optional"
                      ]
                    },
                    "resolve": {
                      "description": "Resolve specifies when this reference should be resolved. The default\nis 'IfNotPresent', which will attempt to resolve the reference only when\nthe corresponding field is not present. Use 'Always' to resolve the\nreference on every reconcile.",
                      "type": "string",
                      "enum": [
                        "Always",
                        "IfNotPresent"
                      ]
                    }
                  },
                  "additionalProperties": false
                }
              },
              "additionalProperties": false
            },
            "inferenceExecutionConfig": {
              "description": "Specifies details of how containers in a multi-container endpoint are called. see Inference Execution Config.",
              "type": "object",
              "properties": {
                "mode": {
                  "description": "The container hosts value SingleModel/MultiModel. The default value is SingleModel.",
                  "type": "string"
                }
              },
              "additionalProperties": false
            },
            "primaryContainer": {
              "description": "The primary docker image containing inference code that is used when the model is deployed for predictions.  If not specified, the container argument is required. Fields are documented below.",
              "type": "object",
              "properties": {
                "containerHostname": {
                  "description": "The DNS host name for the container.",
                  "type": "string"
                },
                "environment": {
                  "description": "Environment variables for the Docker container.\nA list of key value pairs.",
                  "type": "object",
                  "additionalProperties": {
                    "type": "string"
                  },
                  "x-kubernetes-map-type": "granular"
                },
                "image": {
                  "description": "The registry path where the inference code image is stored in Amazon ECR.",
                  "type": "string"
                },
                "imageConfig": {
                  "description": "Specifies whether the model container is in Amazon ECR or a private Docker registry accessible from your Amazon Virtual Private Cloud (VPC). For more information see Using a Private Docker Registry for Real-Time Inference Containers. see Image Config.",
                  "type": "object",
                  "properties": {
                    "repositoryAccessMode": {
                      "description": "Specifies whether the model container is in Amazon ECR or a private Docker registry accessible from your Amazon Virtual Private Cloud (VPC). Allowed values are: Platform and Vpc.",
                      "type": "string"
                    },
                    "repositoryAuthConfig": {
                      "description": "Specifies an authentication configuration for the private docker registry where your model image is hosted. Specify a value for this property only if you specified Vpc as the value for the RepositoryAccessMode field, and the private Docker registry where the model image is hosted requires authentication. see Repository Auth Config.",
                      "type": "object",
                      "properties": {
                        "repositoryCredentialsProviderArn": {
                          "description": "The Amazon Resource Name (ARN) of an AWS Lambda function that provides credentials to authenticate to the private Docker registry where your model image is hosted. For information about how to create an AWS Lambda function, see Create a Lambda function with the console in the AWS Lambda Developer Guide.",
                          "type": "string"
                        }
                      },
                      "additionalProperties": false
                    }
                  },
                  "additionalProperties": false
                },
                "inferenceSpecificationName": {
                  "description": "The inference specification name in the model package version.",
                  "type": "string"
                },
                "mode": {
                  "description": "The container hosts value SingleModel/MultiModel. The default value is SingleModel.",
                  "type": "string"
                },
                "modelDataSource": {
                  "description": "The location of model data to deploy. Use this for uncompressed model deployment. For information about how to deploy an uncompressed model, see Deploying uncompressed models in the AWS SageMaker AI Developer Guide.",
                  "type": "object",
                  "properties": {
                    "s3DataSource": {
                      "description": "The S3 location of model data to deploy.",
                      "type": "array",
                      "items": {
                        "type": "object",
                        "properties": {
                          "compressionType": {
                            "description": "How the model data is prepared. Allowed values are: None and Gzip.",
                            "type": "string"
                          },
                          "modelAccessConfig": {
                            "description": "Specifies the access configuration file for the ML model. You can explicitly accept the model end-user license agreement (EULA) within the [model_access_config configuration block]. see Model Access Config.",
                            "type": "object",
                            "properties": {
                              "acceptEula": {
                                "description": "Specifies agreement to the model end-user license agreement (EULA). The AcceptEula value must be explicitly defined as true in order to accept the EULA that this model requires. You are responsible for reviewing and complying with any applicable license terms and making sure they are acceptable for your use case before downloading or using a model.",
                                "type": "boolean"
                              }
                            },
                            "additionalProperties": false
                          },
                          "s3DataType": {
                            "description": "The type of model data to deploy. Allowed values are: S3Object and S3Prefix.",
                            "type": "string"
                          },
                          "s3Uri": {
                            "description": "The S3 path of model data to deploy.",
                            "type": "string"
                          }
                        },
                        "additionalProperties": false
                      }
                    }
                  },
                  "additionalProperties": false
                },
                "modelDataUrl": {
                  "description": "The URL for the S3 location where model artifacts are stored.",
                  "type": "string"
                },
                "modelPackageName": {
                  "description": "The Amazon Resource Name (ARN) of the model package to use to create the model.",
                  "type": "string"
                },
                "multiModelConfig": {
                  "description": "Specifies additional configuration for multi-model endpoints. see Multi Model Config.",
                  "type": "object",
                  "properties": {
                    "modelCacheSetting": {
                      "description": "Whether to cache models for a multi-model endpoint. By default, multi-model endpoints cache models so that a model does not have to be loaded into memory each time it is invoked. Some use cases do not benefit from model caching. For example, if an endpoint hosts a large number of models that are each invoked infrequently, the endpoint might perform better if you disable model caching. To disable model caching, set the value of this parameter to Disabled. Allowed values are: Enabled and Disabled.",
                      "type": "string"
                    }
                  },
                  "additionalProperties": false
                }
              },
              "additionalProperties": false
            },
            "tags": {
              "description": "Key-value map of resource tags.",
              "type": "object",
              "additionalProperties": {
                "type": "string"
              },
              "x-kubernetes-map-type": "granular"
            },
            "vpcConfig": {
              "description": "Specifies the VPC that you want your model to connect to. VpcConfig is used in hosting services and in batch transform.",
              "type": "object",
              "properties": {
                "securityGroupIds": {
                  "type": "array",
                  "items": {
                    "type": "string"
                  },
                  "x-kubernetes-list-type": "set"
                },
                "subnets": {
                  "type": "array",
                  "items": {
                    "type": "string"
                  },
                  "x-kubernetes-list-type": "set"
                }
              },
              "additionalProperties": false
            }
          },
          "additionalProperties": false
        },
        "managementPolicies": {
          "description": "THIS IS A BETA FIELD. It is on by default but can be opted out\nthrough a Crossplane feature flag.\nManagementPolicies specify the array of actions Crossplane is allowed to\ntake on the managed and external resources.\nSee the design doc for more information: https://github.com/crossplane/crossplane/blob/499895a25d1a1a0ba1604944ef98ac7a1a71f197/design/design-doc-observe-only-resources.md?plain=1#L223\nand this one: https://github.com/crossplane/crossplane/blob/444267e84783136daa93568b364a5f01228cacbe/design/one-pager-ignore-changes.md",
          "type": "array",
          "default": [
            "*"
          ],
          "items": {
            "description": "A ManagementAction represents an action that the Crossplane controllers\ncan take on an external resource.",
            "type": "string",
            "enum": [
              "Observe",
              "Create",
              "Update",
              "Delete",
              "LateInitialize",
              "*"
            ]
          }
        },
        "providerConfigRef": {
          "description": "ProviderConfigReference specifies how the provider that will be used to\ncreate, observe, update, and delete this managed resource should be\nconfigured.",
          "type": "object",
          "default": {
            "kind": "ClusterProviderConfig",
            "name": "default"
          },
          "required": [
            "kind",
            "name"
          ],
          "properties": {
            "kind": {
              "description": "Kind of the referenced object.",
              "type": "string"
            },
            "name": {
              "description": "Name of the referenced object.",
              "type": "string"
            }
          },
          "additionalProperties": false
        },
        "writeConnectionSecretToRef": {
          "description": "WriteConnectionSecretToReference specifies the namespace and name of a\nSecret to which any connection details for this managed resource should\nbe written. Connection details frequently include the endpoint, username,\nand password required to connect to the managed resource.",
          "type": "object",
          "required": [
            "name"
          ],
          "properties": {
            "name": {
              "description": "Name of the secret.",
              "type": "string"
            }
          },
          "additionalProperties": false
        }
      },
      "additionalProperties": false
    },
    "status": {
      "description": "ModelStatus defines the observed state of Model.",
      "type": "object",
      "properties": {
        "atProvider": {
          "type": "object",
          "properties": {
            "arn": {
              "description": "The Amazon Resource Name (ARN) assigned by AWS to this model.",
              "type": "string"
            },
            "container": {
              "description": "Specifies containers in the inference pipeline. If not specified, the primary_container argument is required. Fields are documented below.",
              "type": "array",
              "items": {
                "type": "object",
                "properties": {
                  "containerHostname": {
                    "description": "The DNS host name for the container.",
                    "type": "string"
                  },
                  "environment": {
                    "description": "Environment variables for the Docker container.\nA list of key value pairs.",
                    "type": "object",
                    "additionalProperties": {
                      "type": "string"
                    },
                    "x-kubernetes-map-type": "granular"
                  },
                  "image": {
                    "description": "The registry path where the inference code image is stored in Amazon ECR.",
                    "type": "string"
                  },
                  "imageConfig": {
                    "description": "Specifies whether the model container is in Amazon ECR or a private Docker registry accessible from your Amazon Virtual Private Cloud (VPC). For more information see Using a Private Docker Registry for Real-Time Inference Containers. see Image Config.",
                    "type": "object",
                    "properties": {
                      "repositoryAccessMode": {
                        "description": "Specifies whether the model container is in Amazon ECR or a private Docker registry accessible from your Amazon Virtual Private Cloud (VPC). Allowed values are: Platform and Vpc.",
                        "type": "string"
                      },
                      "repositoryAuthConfig": {
                        "description": "Specifies an authentication configuration for the private docker registry where your model image is hosted. Specify a value for this property only if you specified Vpc as the value for the RepositoryAccessMode field, and the private Docker registry where the model image is hosted requires authentication. see Repository Auth Config.",
                        "type": "object",
                        "properties": {
                          "repositoryCredentialsProviderArn": {
                            "description": "The Amazon Resource Name (ARN) of an AWS Lambda function that provides credentials to authenticate to the private Docker registry where your model image is hosted. For information about how to create an AWS Lambda function, see Create a Lambda function with the console in the AWS Lambda Developer Guide.",
                            "type": "string"
                          }
                        },
                        "additionalProperties": false
                      }
                    },
                    "additionalProperties": false
                  },
                  "inferenceSpecificationName": {
                    "description": "The inference specification name in the model package version.",
                    "type": "string"
                  },
                  "mode": {
                    "description": "The container hosts value SingleModel/MultiModel. The default value is SingleModel.",
                    "type": "string"
                  },
                  "modelDataSource": {
                    "description": "The location of model data to deploy. Use this for uncompressed model deployment. For information about how to deploy an uncompressed model, see Deploying uncompressed models in the AWS SageMaker AI Developer Guide.",
                    "type": "object",
                    "properties": {
                      "s3DataSource": {
                        "description": "The S3 location of model data to deploy.",
                        "type": "array",
                        "items": {
                          "type": "object",
                          "properties": {
                            "compressionType": {
                              "description": "How the model data is prepared. Allowed values are: None and Gzip.",
                              "type": "string"
                            },
                            "modelAccessConfig": {
                              "description": "Specifies the access configuration file for the ML model. You can explicitly accept the model end-user license agreement (EULA) within the [model_access_config configuration block]. see Model Access Config.",
                              "type": "object",
                              "properties": {
                                "acceptEula": {
                                  "description": "Specifies agreement to the model end-user license agreement (EULA). The AcceptEula value must be explicitly defined as true in order to accept the EULA that this model requires. You are responsible for reviewing and complying with any applicable license terms and making sure they are acceptable for your use case before downloading or using a model.",
                                  "type": "boolean"
                                }
                              },
                              "additionalProperties": false
                            },
                            "s3DataType": {
                              "description": "The type of model data to deploy. Allowed values are: S3Object and S3Prefix.",
                              "type": "string"
                            },
                            "s3Uri": {
                              "description": "The S3 path of model data to deploy.",
                              "type": "string"
                            }
                          },
                          "additionalProperties": false
                        }
                      }
                    },
                    "additionalProperties": false
                  },
                  "modelDataUrl": {
                    "description": "The URL for the S3 location where model artifacts are stored.",
                    "type": "string"
                  },
                  "modelPackageName": {
                    "description": "The Amazon Resource Name (ARN) of the model package to use to create the model.",
                    "type": "string"
                  },
                  "multiModelConfig": {
                    "description": "Specifies additional configuration for multi-model endpoints. see Multi Model Config.",
                    "type": "object",
                    "properties": {
                      "modelCacheSetting": {
                        "description": "Whether to cache models for a multi-model endpoint. By default, multi-model endpoints cache models so that a model does not have to be loaded into memory each time it is invoked. Some use cases do not benefit from model caching. For example, if an endpoint hosts a large number of models that are each invoked infrequently, the endpoint might perform better if you disable model caching. To disable model caching, set the value of this parameter to Disabled. Allowed values are: Enabled and Disabled.",
                        "type": "string"
                      }
                    },
                    "additionalProperties": false
                  }
                },
                "additionalProperties": false
              }
            },
            "enableNetworkIsolation": {
              "description": "Isolates the model container. No inbound or outbound network calls can be made to or from the model container.",
              "type": "boolean"
            },
            "executionRoleArn": {
              "description": "A role that SageMaker AI can assume to access model artifacts and docker images for deployment.",
              "type": "string"
            },
            "id": {
              "type": "string"
            },
            "inferenceExecutionConfig": {
              "description": "Specifies details of how containers in a multi-container endpoint are called. see Inference Execution Config.",
              "type": "object",
              "properties": {
                "mode": {
                  "description": "The container hosts value SingleModel/MultiModel. The default value is SingleModel.",
                  "type": "string"
                }
              },
              "additionalProperties": false
            },
            "primaryContainer": {
              "description": "The primary docker image containing inference code that is used when the model is deployed for predictions.  If not specified, the container argument is required. Fields are documented below.",
              "type": "object",
              "properties": {
                "containerHostname": {
                  "description": "The DNS host name for the container.",
                  "type": "string"
                },
                "environment": {
                  "description": "Environment variables for the Docker container.\nA list of key value pairs.",
                  "type": "object",
                  "additionalProperties": {
                    "type": "string"
                  },
                  "x-kubernetes-map-type": "granular"
                },
                "image": {
                  "description": "The registry path where the inference code image is stored in Amazon ECR.",
                  "type": "string"
                },
                "imageConfig": {
                  "description": "Specifies whether the model container is in Amazon ECR or a private Docker registry accessible from your Amazon Virtual Private Cloud (VPC). For more information see Using a Private Docker Registry for Real-Time Inference Containers. see Image Config.",
                  "type": "object",
                  "properties": {
                    "repositoryAccessMode": {
                      "description": "Specifies whether the model container is in Amazon ECR or a private Docker registry accessible from your Amazon Virtual Private Cloud (VPC). Allowed values are: Platform and Vpc.",
                      "type": "string"
                    },
                    "repositoryAuthConfig": {
                      "description": "Specifies an authentication configuration for the private docker registry where your model image is hosted. Specify a value for this property only if you specified Vpc as the value for the RepositoryAccessMode field, and the private Docker registry where the model image is hosted requires authentication. see Repository Auth Config.",
                      "type": "object",
                      "properties": {
                        "repositoryCredentialsProviderArn": {
                          "description": "The Amazon Resource Name (ARN) of an AWS Lambda function that provides credentials to authenticate to the private Docker registry where your model image is hosted. For information about how to create an AWS Lambda function, see Create a Lambda function with the console in the AWS Lambda Developer Guide.",
                          "type": "string"
                        }
                      },
                      "additionalProperties": false
                    }
                  },
                  "additionalProperties": false
                },
                "inferenceSpecificationName": {
                  "description": "The inference specification name in the model package version.",
                  "type": "string"
                },
                "mode": {
                  "description": "The container hosts value SingleModel/MultiModel. The default value is SingleModel.",
                  "type": "string"
                },
                "modelDataSource": {
                  "description": "The location of model data to deploy. Use this for uncompressed model deployment. For information about how to deploy an uncompressed model, see Deploying uncompressed models in the AWS SageMaker AI Developer Guide.",
                  "type": "object",
                  "properties": {
                    "s3DataSource": {
                      "description": "The S3 location of model data to deploy.",
                      "type": "array",
                      "items": {
                        "type": "object",
                        "properties": {
                          "compressionType": {
                            "description": "How the model data is prepared. Allowed values are: None and Gzip.",
                            "type": "string"
                          },
                          "modelAccessConfig": {
                            "description": "Specifies the access configuration file for the ML model. You can explicitly accept the model end-user license agreement (EULA) within the [model_access_config configuration block]. see Model Access Config.",
                            "type": "object",
                            "properties": {
                              "acceptEula": {
                                "description": "Specifies agreement to the model end-user license agreement (EULA). The AcceptEula value must be explicitly defined as true in order to accept the EULA that this model requires. You are responsible for reviewing and complying with any applicable license terms and making sure they are acceptable for your use case before downloading or using a model.",
                                "type": "boolean"
                              }
                            },
                            "additionalProperties": false
                          },
                          "s3DataType": {
                            "description": "The type of model data to deploy. Allowed values are: S3Object and S3Prefix.",
                            "type": "string"
                          },
                          "s3Uri": {
                            "description": "The S3 path of model data to deploy.",
                            "type": "string"
                          }
                        },
                        "additionalProperties": false
                      }
                    }
                  },
                  "additionalProperties": false
                },
                "modelDataUrl": {
                  "description": "The URL for the S3 location where model artifacts are stored.",
                  "type": "string"
                },
                "modelPackageName": {
                  "description": "The Amazon Resource Name (ARN) of the model package to use to create the model.",
                  "type": "string"
                },
                "multiModelConfig": {
                  "description": "Specifies additional configuration for multi-model endpoints. see Multi Model Config.",
                  "type": "object",
                  "properties": {
                    "modelCacheSetting": {
                      "description": "Whether to cache models for a multi-model endpoint. By default, multi-model endpoints cache models so that a model does not have to be loaded into memory each time it is invoked. Some use cases do not benefit from model caching. For example, if an endpoint hosts a large number of models that are each invoked infrequently, the endpoint might perform better if you disable model caching. To disable model caching, set the value of this parameter to Disabled. Allowed values are: Enabled and Disabled.",
                      "type": "string"
                    }
                  },
                  "additionalProperties": false
                }
              },
              "additionalProperties": false
            },
            "region": {
              "description": "Region where this resource will be managed. Defaults to the Region set in the provider configuration.\nRegion is the region you'd like your resource to be created in.",
              "type": "string"
            },
            "tags": {
              "description": "Key-value map of resource tags.",
              "type": "object",
              "additionalProperties": {
                "type": "string"
              },
              "x-kubernetes-map-type": "granular"
            },
            "tagsAll": {
              "description": "A map of tags assigned to the resource, including those inherited from the provider default_tags configuration block.",
              "type": "object",
              "additionalProperties": {
                "type": "string"
              },
              "x-kubernetes-map-type": "granular"
            },
            "vpcConfig": {
              "description": "Specifies the VPC that you want your model to connect to. VpcConfig is used in hosting services and in batch transform.",
              "type": "object",
              "properties": {
                "securityGroupIds": {
                  "type": "array",
                  "items": {
                    "type": "string"
                  },
                  "x-kubernetes-list-type": "set"
                },
                "subnets": {
                  "type": "array",
                  "items": {
                    "type": "string"
                  },
                  "x-kubernetes-list-type": "set"
                }
              },
              "additionalProperties": false
            }
          },
          "additionalProperties": false
        },
        "conditions": {
          "description": "Conditions of the resource.",
          "type": "array",
          "items": {
            "description": "A Condition that may apply to a resource.",
            "type": "object",
            "required": [
              "lastTransitionTime",
              "reason",
              "status",
              "type"
            ],
            "properties": {
              "lastTransitionTime": {
                "description": "LastTransitionTime is the last time this condition transitioned from one\nstatus to another.",
                "type": "string",
                "format": "date-time"
              },
              "message": {
                "description": "A Message containing details about this condition's last transition from\none status to another, if any.",
                "type": "string"
              },
              "observedGeneration": {
                "description": "ObservedGeneration represents the .metadata.generation that the condition was set based upon.\nFor instance, if .metadata.generation is currently 12, but the .status.conditions[x].observedGeneration is 9, the condition is out of date\nwith respect to the current state of the instance.",
                "type": "integer",
                "format": "int64"
              },
              "reason": {
                "description": "A Reason for this condition's last transition from one status to another.",
                "type": "string"
              },
              "status": {
                "description": "Status of this condition; is it currently True, False, or Unknown?",
                "type": "string"
              },
              "type": {
                "description": "Type of this condition. At most one of each condition type may apply to\na resource at any point in time.",
                "type": "string"
              }
            },
            "additionalProperties": false
          },
          "x-kubernetes-list-map-keys": [
            "type"
          ],
          "x-kubernetes-list-type": "map"
        },
        "observedGeneration": {
          "description": "ObservedGeneration is the latest metadata.generation\nwhich resulted in either a ready state, or stalled due to error\nit can not recover from without human intervention.",
          "type": "integer",
          "format": "int64"
        }
      },
      "additionalProperties": false
    }
  }
}
